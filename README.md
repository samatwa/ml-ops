# Основи MLOps: Docker та налаштування середовища

Цей проєкт демонструє основи створення та оптимізації Docker-образів для застосунку машинного навчання. Він включає:
- Простий скрипт для інференсу (`inference.py`), що використовує попередньо навчену модель PyTorch.
- "Fat" Docker-образ (`Dockerfile.fat`), що містить усі інструменти для збірки.
- "Slim" Docker-образ (`Dockerfile.slim`), оптимізований за допомогою багатоетапної збірки.
- Скрипт для встановлення (`install_dev_tools.sh`) для налаштування локального середовища розробки.

## Як запустити

Існує два способи запуску скрипту: безпосередньо за допомогою Python або через Docker.

### 1. Запуск з Python (локальне середовище)

Спочатку переконайтеся, що у вас встановлені всі необхідні інструменти та бібліотеки. Ви можете використати наданий скрипт для цього в системі Linux на базі Debian:

```bash
# Зробити скрипт виконуваним
chmod +x install_dev_tools.sh

# Запустити скрипт встановлення
./install_dev_tools.sh
```

Після налаштування середовища ви можете запустити скрипт, передавши йому шлях до зображення:

```bash
python inference.py /шлях/до/вашого/зображення.jpg
```

### 2. Запуск з Docker

Це рекомендований спосіб, оскільки він не вимагає жодних локальних установок, крім Docker.

**Збірка образу:**

Ви можете зібрати "fat" або "slim" образ. Рекомендується використовувати `slim`.

```bash
# Зібрати slim-образ
docker build -f Dockerfile.slim -t ml-slim .

# (Опціонально) Зібрати fat-образ
docker build -f Dockerfile.fat -t ml-fat .
```

**Запуск контейнера:**

Запустіть інференс, змонтувавши поточну директорію (яка містить ваші зображення) в контейнер.

```bash
# Переконайтеся, що зображення для тестування знаходиться в поточній директорії
# Наприклад: example.jpg

# Запустити інференс за допомогою slim-образу або fat-образу
docker run --rm -v "$(pwd):/app" ml-slim example.jpg
docker run --rm -v "${PWD}:/app" ml-fat /app/example.jpg 
```

Скрипт виведе топ-3 прогнозовані класи для зображення.

