# Звіт: Порівняння Docker-образів `ml-fat` та `ml-slim`

## 1. Порівняльна таблиця

На основі проведених збірок ми отримали два образи з наступними характеристиками:

| Параметр            | `ml-fat`                            | `ml-slim`                       | Різниця                  |
| ------------------- | ------------------------------------| --------------------------------| ------------------------ |
| **Розмір**          | **2.06 GB**                         | **1.43 GB**                     | **-630 MB (-30%)**       |
| **Кількість шарів** | ~8-10 (ОС, build-tools, залежності) | ~5-7 (лише ОС, залежності, код) | Менше проміжних шарів    |

**Висновок:** Багатоетапна збірка (`multi-stage build`) дозволила зменшити розмір фінального образу на **630 МБ**, що є чудовим результатом оптимізації.

## 2. Проблеми "жирного" образу (`ml-fat`)

"Жирний" підхід, хоч і простий у реалізації, має низку суттєвих недоліків:

1.  **Зайві залежності:** Образ `ml-fat` містить інструменти для збірки (`build-essential`, компілятори `gcc` тощо), які абсолютно непотрібні для запуску програми. Це створює потенційні ризики безпеки та безпідставно збільшує розмір.
2.  **Великий обсяг:** Розмір 2.06 GB є надлишковим. Це призводить до повільного завантаження образу з репозиторіїв (docker pull), довшого процесу CI/CD та займає більше місця на дисках розробників і серверів.
3.  **Повільніші збірки:** Хоча `ml-fat` збирається за один етап, будь-яка зміна у коді чи залежностях призводить до тривалого повторного встановлення всіх пакетів, оскільки кешування шарів `pip` менш ефективне.

## 3. Поради щодо подальшої оптимізації

Незважаючи на успішне застосування multi-stage build, існують кроки для подальшого "схуднення" образу `ml-slim`:

1.  **Використання `distroless` образу:** Замість `python:3.10-slim` можна використати `gcr.io/distroless/python3-debian11` як фінальний образ. Distroless-образи містять лише додаток та його runtime-залежності, без менеджера пакетів, оболонки (shell) чи інших програм, що мінімізує розмір та поверхню атаки.
2.  **Оптимізація моделі:** Найбільшу частину образу, ймовірно, займають бібліотеки `torch` та сама модель. Можна:
    *   **Конвертувати модель у TorchScript Lite:** Це спеціальний формат для мобільних та edge-пристроїв, який значно легший.
    *   **Застосувати квантизацію (Quantization):** Зменшення точності вагів моделі (наприклад, з FP32 до INT8) може кардинально зменшити її розмір майже без втрати точності.
3.  **Аналіз та зменшення залежностей:** Перевірити, чи дійсно потрібні всі компоненти `torch` та `torchvision`. Іноді можна обійтися менш функціональними, але значно легшими пакетами, якщо використовується лише обмежений набір функцій.